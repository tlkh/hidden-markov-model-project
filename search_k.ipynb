{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import emission\n",
    "import transition\n",
    "import viterbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_f_list = []\n",
    "sentiment_f_list = []\n",
    "vocab_size = []\n",
    "new_vocab = []\n",
    "k_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_k(k):\n",
    "    print(\">> Test k =\", k)\n",
    "    dataset_folder = \"data/AL/\"\n",
    "    train_data = dataset_folder + \"train\"\n",
    "    lines = utils.read_file_to_lines(train_data)\n",
    "    \n",
    "    emission_data = emission.generate_emission_table(lines)\n",
    "    \n",
    "    hashmap = emission_data[\"x_hashmap\"]\n",
    "    word_freq = emission_data[\"x_word_freq\"]\n",
    "    smoothed_hashmap = utils.add_unk(hashmap, word_freq, k=k)\n",
    "    emission_data[\"x_hashmap\"] = smoothed_hashmap\n",
    "\n",
    "    x_vocab = utils.get_emission_vocab(smoothed_hashmap)\n",
    "    vocab_size.append(len(x_vocab))\n",
    "    \n",
    "    transition_pairs = transition.generate_transition_pairs(lines)\n",
    "    \n",
    "    y_pairs = transition_pairs[\"Y_pairs\"]\n",
    "    y_vocab = transition_pairs[\"y_vocab\"]\n",
    "    y_freq = transition_pairs[\"y_freq\"]\n",
    "    \n",
    "    transition_data = transition.generate_transition_data(y_pairs, y_vocab)\n",
    "    \n",
    "    hmm = viterbi.HMM()\n",
    "    hmm.fit_word_tokenizer(x_vocab)\n",
    "    hmm.fit_pos_tokenizer(y_vocab)\n",
    "    hmm.build_transition_weights(y_freq, transition_data)\n",
    "    hmm.build_emission_weights(emission_data)\n",
    "    \n",
    "    train_data = dataset_folder + \"dev.in\"\n",
    "    lines = utils.read_file_to_lines(train_data)\n",
    "\n",
    "    sentences = []\n",
    "\n",
    "    while len(lines) > 1:\n",
    "        sentence_break = lines.index(\"\")\n",
    "        sentence_xy = lines[:sentence_break]\n",
    "        words = [utils.preprocess_text(token)\n",
    "                 for token in sentence_xy]\n",
    "        sentence = \" \".join(words).strip()\n",
    "        sentences.append(sentence)\n",
    "        lines = lines[sentence_break+1:]\n",
    "        \n",
    "    new_words = []\n",
    "    for line in sentences:\n",
    "        for word in line.split(\" \"):\n",
    "            if word not in x_vocab:\n",
    "                new_words.append(word)\n",
    "\n",
    "    new_words = list(set(new_words))\n",
    "    new_words.sort()\n",
    "    new_vocab.append(len(new_words))\n",
    "    \n",
    "    # only for the progress bar!\n",
    "    try:\n",
    "        from tqdm import tqdm\n",
    "        USE_TQDM = True\n",
    "    except Exception as e:\n",
    "        print(e, \"TQDM import error, disable progress bar\")\n",
    "\n",
    "    if USE_TQDM:\n",
    "        sentences_it = tqdm(sentences)\n",
    "    else:\n",
    "        sentences_it = sentences\n",
    "        \n",
    "    preds = []\n",
    "\n",
    "    for line in sentences_it:\n",
    "        pred = hmm.viterbi_predict(line)\n",
    "        pred = hmm.pos_tokens_to_labels(pred)\n",
    "        preds.append(pred)\n",
    "\n",
    "    assert len(sentences) == len(preds)\n",
    "    \n",
    "    outfile = dataset_folder + \"dev.p5.out\"\n",
    "\n",
    "    with open(outfile, \"w\") as f:\n",
    "        for sentence, pred in zip(sentences, preds):\n",
    "            word_array = sentence.split(\" \")\n",
    "            try:\n",
    "                assert len(word_array) == len(pred)\n",
    "                for i, word in enumerate(word_array):\n",
    "                    f.write(word + \" \" + pred[i] +\"\\n\")\n",
    "            except:\n",
    "                print(word_array)\n",
    "                print(pred)\n",
    "                break\n",
    "            f.write(\"\\n\")\n",
    "    \n",
    "    gold_data = dataset_folder + \"dev.out\"\n",
    "    pred_data = dataset_folder + \"dev.p5.out\"\n",
    "\n",
    "    data = utils.run_eval(gold_data, pred_data)\n",
    "    \n",
    "    entity_f_list.append(data[\"entity_f\"])\n",
    "    sentiment_f_list.append(data[\"sentiment_f\"])\n",
    "    k_list.append(k)\n",
    "\n",
    "    print(\"Results\")\n",
    "    print(\"Entity F:\", data[\"entity_f\"])\n",
    "    print(\"Sentiment F:\", data[\"sentiment_f\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Test k = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1492/1492 [02:04<00:00, 12.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "Entity F: 0.5933\n",
      "Sentiment F: 0.4957\n",
      ">> Test k = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1492/1492 [01:59<00:00, 12.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "Entity F: 0.6002\n",
      "Sentiment F: 0.5135\n",
      ">> Test k = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1492/1492 [01:57<00:00, 12.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "Entity F: 0.6011\n",
      "Sentiment F: 0.5165\n",
      ">> Test k = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1492/1492 [01:59<00:00, 12.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "Entity F: 0.6021\n",
      "Sentiment F: 0.5178\n",
      ">> Test k = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1492/1492 [02:00<00:00, 12.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "Entity F: 0.6021\n",
      "Sentiment F: 0.5175\n",
      ">> Test k = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1492/1492 [02:03<00:00, 12.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "Entity F: 0.6026\n",
      "Sentiment F: 0.5174\n",
      ">> Test k = 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1492/1492 [01:58<00:00, 12.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results\n",
      "Entity F: 0.6025\n",
      "Sentiment F: 0.5172\n",
      ">> Test k = 8\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/Documents/Github/50k-free-labour/transition.py\u001b[0m in \u001b[0;36mgenerate_transition_pairs\u001b[0;34m(lines)\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0;31m# x is word, y is POS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mcurrent_Y\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-8a9f75ddb129>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrun_k\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-7f7e62c741b4>\u001b[0m in \u001b[0;36mrun_k\u001b[0;34m(k)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mvocab_size\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_vocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtransition_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_transition_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0my_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransition_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Y_pairs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Github/50k-free-labour/transition.py\u001b[0m in \u001b[0;36mgenerate_transition_pairs\u001b[0;34m(lines)\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpairs_Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0my_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_tokens\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcurrent_Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0my_freq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"##START##\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0my_freq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"##END##\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mcurrent_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Invalid alias: The name clear can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name more can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name less can't be aliased because it is another magic command.\n",
      "ERROR:root:Invalid alias: The name man can't be aliased because it is another magic command.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 10):\n",
    "    run_k(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = \"retina\"\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(k_list, entity_f_list, label=\"Entity F\")\n",
    "plt.plot(k_list, sentiment_f_list, label=\"Sentiment F\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.ylim(0.7, 0.9)\n",
    "plt.title(dataset_folder + \"F Scores\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(k_list, vocab_size, label=\"Vocab Size\")\n",
    "plt.plot(k_list, new_vocab, label=\"New Vocab\")\n",
    "plt.xlabel(\"k\")\n",
    "plt.title(dataset_folder + \" Vocab Sizes\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
