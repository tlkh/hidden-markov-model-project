{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import viterbi\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOWER = True\n",
    "NORM_TENSE = True\n",
    "REP_NUM = True\n",
    "REP_YEAR = True\n",
    "REP_SYM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"data/EN/\"\n",
    "train_data = dataset_folder + \"train\"\n",
    "lines = utils.read_file_to_lines(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "pos_tags = []\n",
    "\n",
    "while len(lines) > 1:\n",
    "    sentence_break = lines.index(\"\")\n",
    "    sentence_xy = lines[:sentence_break]\n",
    "    words = [utils.preprocess_text(token.split(\" \")[0],\n",
    "                                   lower=LOWER,\n",
    "                                   norm_tense=NORM_TENSE,\n",
    "                                   replace_number=REP_NUM,\n",
    "                                   replace_year=REP_YEAR,\n",
    "                                   replace_symbol=REP_SYM)\n",
    "             for token in sentence_xy]\n",
    "    pos = [token.split(\" \")[1] for token in sentence_xy]\n",
    "    sentences.append(words)\n",
    "    pos_tags.append(pos)\n",
    "    lines = lines[sentence_break+1:]\n",
    "    \n",
    "corpus = []\n",
    "for line in sentences:\n",
    "    corpus += line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = viterbi.Tokenizer()\n",
    "word_tokenizer.fit_on_text(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_list = []\n",
    "\n",
    "target = []\n",
    "context = []\n",
    "\n",
    "for sentence, pos_tag in zip(sentences, pos_tags):\n",
    "    len_sentence = len(sentence)\n",
    "    for i in range(len_sentence):\n",
    "        try:\n",
    "            if pos_tag[i].split(\"-\")[1] == \"NP\":\n",
    "                np_list.append(sentence[i])\n",
    "        except:\n",
    "            pass\n",
    "            \n",
    "np_list = list(set(np_list))\n",
    "np_list.sort()\n",
    "vocab_size = len(word_tokenizer.vocab_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_o_matrix = np.zeros((vocab_size, vocab_size))\n",
    "\n",
    "for sentence, pos_tag in zip(sentences, pos_tags):\n",
    "    np_list = []\n",
    "    len_sentence = len(sentence)\n",
    "    sentence = word_tokenizer.return_sequence(\" \".join(sentence))\n",
    "    for i in range(len_sentence):\n",
    "        try:\n",
    "            if pos_tag[i].split(\"-\")[1] == \"NP\":\n",
    "                np_list.append(sentence[i])\n",
    "        except:\n",
    "            pass\n",
    "    for i in np_list:\n",
    "        for j in np_list:\n",
    "            co_o_matrix[i][j] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0., 54.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0., 36., ...,  0.,  0.,  0.],\n",
       "       ...,\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  0., ...,  0.,  0.,  4.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_o_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
