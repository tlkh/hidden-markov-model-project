{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOWER = True\n",
    "NORM_TENSE = True\n",
    "REP_NUM = True\n",
    "REP_YEAR = True\n",
    "REP_SYM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = \"data/AL/\"\n",
    "train_data = dataset_folder + \"train\"\n",
    "lines = utils.read_file_to_lines(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = []\n",
    "pos_tags = []\n",
    "\n",
    "while len(lines) > 1:\n",
    "    sentence_break = lines.index(\"\")\n",
    "    sentence_xy = lines[:sentence_break]\n",
    "    words = [utils.preprocess_al_text(token.split(\" \")[0],\n",
    "                                      lower=LOWER, replace_number=REP_NUM)\n",
    "             for token in sentence_xy]\n",
    "    pos = [token.split(\" \")[1] for token in sentence_xy]\n",
    "    sentences.append(words)\n",
    "    pos_tags.append(pos)\n",
    "    lines = lines[sentence_break+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_categories = [\n",
    "    'CITY', 'COMMUNITY', 'COUNTRY', 'DISTRICT', 'POI', 'PROV', 'REDUNDANT', 'ROAD', 'TOWN'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_words = []\n",
    "\n",
    "def get_entities(sentence, pos_tag):\n",
    "    for i in range(len(sentence)):\n",
    "        try:\n",
    "            pos = pos_tag[i].split(\"-\")[1]\n",
    "            word = sentence[i]\n",
    "            if pos in name_categories:\n",
    "                if len(word) < 2:\n",
    "                    name_words.append(word)\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        \n",
    "for n in range(len(sentences)):\n",
    "    sentence = sentences[n]\n",
    "    pos_tag = pos_tags[n]\n",
    "    get_entities(sentence, pos_tag)\n",
    "    \n",
    "def clean_list(input_list):\n",
    "    input_list = list(set(input_list))\n",
    "    input_list.sort()\n",
    "    return input_list\n",
    "\n",
    "name_words = clean_list(name_words)\n",
    "len_name_words = len(name_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from random import randint, choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_bool():\n",
    "    return choice([True, False])\n",
    "\n",
    "def augment_line(sentence, pos_tag):\n",
    "    start = False\n",
    "    for i, word in enumerate(sentence):\n",
    "        try:\n",
    "            b, pos = pos_tag[i].split(\"-\")\n",
    "            if pos in name_categories:\n",
    "                r_i = randint(0, len_name_words)\n",
    "                sentence[i] = name_words[r_i]\n",
    "        except:\n",
    "            pass\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "org: 灏 娓 鍥 鏂 瀹 鍥 1-4 骞 1-6 瀹\n",
      "aug: 鐏 璁 绂 姘 瀣 钖 1-4 骞 1-6 瀹\n",
      "\n",
      "org: 鍢 鍏 鍗 婀 鍖 鏂 鏄 璺 鏂 鏂 鍖 骞 鍦 鐢 鑱\n",
      "aug: - 婧 鎼 寰 璺 绯 閾 m 鐖 鎸 楗 闃 鍞 楂 閱\n",
      "\n",
      "org: 娴 姹 鐪 瀹 娉 甯 娴 鏇 鍖 鐧 鏉 琛 4-4 寮 1-5 鍙 闃 鍏 澶 鑽 鎴\n",
      "aug: 瀹 鐩 鑻 鍜 骞 濞 涓 娓 h 閴 鎽 鎷 4-4 寮 1-5 鍙 纭 鎰 鐥 瑜 鍗\n",
      "\n",
      "org: 娴 姹 鐪 瀹 娉 甯 闀 娴 鍖 闀 娴 鍖 閽 鍖 璺 3-3 鍙 鍚 鐢 鍥 闄 鍩 6-5 骞 鏋 绌 灞 涓 宸\n",
      "aug: 鍩 妗 澧 浼 妲 娌 鐩 瑜 鐭 鐭 鍎 鏉 鎯 姘 鏄 3-3 鍙 瀣 绁 缍 璺 鍜 6-5 骞 鏋 绌 灞 涔 铻\n",
      "\n",
      "org: 娓 宸 涔 娓 鏌 甯 闀 铦 涓 鐗 娴 鍥 涔 涔 涓 绾\n",
      "aug: 宕 鑽 鍓 鍍 g l 鐦 h 绫 j 鎼 鍥 涔 涔 涓 绾\n",
      "\n",
      "org: 娴 姹 鐪 鍢 鍏 甯 娴 瀹 甯 鏂 妗 闀 鏃 灏 浜 涓 鍥 鍖 8-4 骞\n",
      "aug: 鐘 鍧 钀 鍕 瑙 婢 浠 鑻 瓒 鏂 鏌 娼 瀚 钀 鍏 鍏 铓 鐒 8-4 骞\n",
      "\n",
      "org: 娴 姹 鐪 鏉 宸 甯 浣 鏉 鍖 涓 骞 鍗 鑻 琛 閬 鍗 澶 琛 9-4 鍙 浣 鏉 鍐 鍟 浜 鍔 璧 婧 閮\n",
      "aug: 铻 铦 鍑 閰 鐧 鍧 璞 杞 鍑 閬 妲 鐧 鍕 e 鐥 鍗 澶 琛 9-4 鍙 韬 椴 h 鍑 鐐 璋 宥 铏 璁\n",
      "\n",
      "org: 鍜 涔 璺 1-5 鍙 姹 閲 澶 鍘 1-6\n",
      "aug: 鐥 娆 鏌 1-5 鍙 搴 婀 楹 鍟 1-6\n",
      "\n",
      "org: 娴 姹 鐪 婀 宸 甯 绾 鏃 璺 1-6 鍙 婀 宸 甯 涓 蹇 鍖 闄\n",
      "aug: 鎻 鐧 娼 e 鑲 宸 绁 j 缂 1-6 鍙 灏 鏄 宀 瑗 u 缈 绡\n",
      "\n",
      "org: 鑻 鍗 榫 娓 鍒 鍗 NUM-THING 鍙\n",
      "aug: 宀 浼 婕 琚 閾 浣 NUM-THING 鍙\n",
      "\n",
      "org: 涓 娴 甯 闂 鍖 鍖 娌 鍗 鍖 璺 1-6 鍙\n",
      "aug: 妗 绂 鍧 鏋 u 楗 妯 瑷 f 鐏 1-6 鍙\n",
      "\n",
      "org: 涓 娴 甯 娴 涓 鍖 搴 妗 闀 绉 娴 璺 3-6 寮 鍒 鐮 鏅 閫 1-5 鍙 d 1-4 妤 濞 绾 浼 涓\n",
      "aug: 涔 娲 淇 搴 绫 鐚 鐥 璐 鐑 鐕 鎮 閴 3-6 寮 涔 鍠 鍓 鐨 1-5 鍙 d 1-4 妤 濞 绾 浼 涓\n",
      "\n",
      "org: 杞 绔 澶 閬 1-6 鏅 鎱 璋 娓 宸 鏂 鍖 鍒 鎰 鍥 i 鏍 7-5 瀹\n",
      "aug: 鏅 鎰 鍓 榻 1-6 鍠 濞 瀹 鐒 铻 铫 鎱 鑽 缁 鐮 i 鏍 7-5 瀹\n",
      "\n",
      "org: 娴 姹 鐪 鏉 宸 姹 骞 鍖 绉 娑 鍖 璺 涓 鍗 澶 杩 鑺 鍥 1-4 - 1-4 - 2-6\n",
      "aug: 宥 l 鍩 閰 鎻 濠 鐪 浠 锠 鑼 缃 鎮 - 闅 瀹 m 鑲 濮 1-4 榄 1-4 妾 2-6\n",
      "\n",
      "org: 缁 鍏 甯 璇 鏆 甯 搴 鍙 闀 涓 澶 璺 3-5\n",
      "aug: 姘 璋 濉 鐥 鎻 鐟 鑽 鎿 鍊 榄 閯 k 3-5\n",
      "\n",
      "org: 涔 涔 甯 鍟 鍩 澶 閬 閲 鍩 楂 灏 澶 1-3 鍖 7-3 - 1-6\n",
      "aug: 铚 銆 婀 婀 闃 鍌 鏉 妗 濉 杞 s 绾 1-3 鍖 7-3 閫 1-6\n",
      "\n",
      "org: 娴 姹 鐪 鏉 宸 姹 骞 鍖 骞 绂 鍗 璺 8-3 鍙 鍏 鍙 妤 浜 妤 涓 浜 鍒 涓 缁 绉 鎶 鏈 闄 鍏 鍙\n",
      "aug: _ 妲 鑷 鍚 鎳 姹 鐟 绐 锠 棣 婢 鍗 8-3 鍙 鍏 鍙 妤 浜 妤 涓 浜 鍒 涓 缁 绉 鎶 鏈 闄 鍏 鍙\n",
      "\n",
      "org: 娴 姹 鐪 鏉 宸 甯 浣 鏉 鍖 涓 骞 琛 閬 鍖 澶 琛 NUM-THING 鍙 涓 妤\n",
      "aug: 閿 鏂 鐮 s 鑾 鍢 姣 鏂 铓 鍖 娲 璋 j 绨 纭 宀 NUM-THING 鍙 涓 妤\n",
      "\n",
      "org: 娴 娌 琛 閬 涓 淇 澶 閬 1-6 鍙\n",
      "aug: 鏅 绗 閱 锜 琛 b ? 鑲 1-6 鍙\n",
      "\n",
      "org: 娴 姹 鐪 鏉 宸 甯 姹 骞 鍖 涓 娌 骞 绂 鍗 璺 9-3 鍙 涓 浜 鍒 宸 涓 鍥 1-4 骞 9-3 妤\n",
      "aug: 铻 ? 妤 婧 鑱 寤 浜 鏄 楣 宓 蹇 楸 寰 澧 姣 9-3 鍙 f d 绁 闇 瀵 瑙 1-4 骞 9-3 妤\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aug_lines = []\n",
    "\n",
    "#for n in range(len(sentences)):\n",
    "for n in range(20):\n",
    "    sentence = sentences[n]\n",
    "    sentence = copy.deepcopy(sentence)\n",
    "    print(\"org:\", \" \".join(sentence))\n",
    "    pos_tag = pos_tags[n]\n",
    "    sentence = augment_line(sentence, pos_tag)\n",
    "    for i, word in enumerate(sentence):\n",
    "        pos = pos_tag[i]\n",
    "        line = word + \" \" + pos\n",
    "        aug_lines.append(line)\n",
    "    print(\"aug:\", \" \".join(sentence))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aug_lines[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
